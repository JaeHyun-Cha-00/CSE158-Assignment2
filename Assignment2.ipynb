{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load data\n",
        "dataVer10 = \"review-Vermont-10.json.gz\"\n",
        "dataVer = \"review-Vermont.json.gz\"\n",
        "dataMeta = \"meta-Vermont.json.gz\"\n",
        "\n",
        "df_meta = pd.read_json(dataMeta, lines=True, compression=\"gzip\")\n",
        "df_ver = pd.read_json(dataVer, lines=True, compression=\"gzip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "HgjPAwlhf4bK",
        "outputId": "ce9027be-97c1-4fdc-e2e6-0bd2a803d032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before removing missing text: 853549\n",
            "After removing missing text: 508108\n",
            "Before removing duplicates: 508108\n",
            "After removing duplicates: 488212\n",
            "Before removing missing ratings: 488212\n",
            "After removing missing ratings: 488052\n",
            "Preprocessed data saved to merged.csv\n"
          ]
        }
      ],
      "source": [
        "# Merge and preprocess data\n",
        "df = df_ver.merge(df_meta, on=\"gmap_id\", how=\"left\")\n",
        "\n",
        "print(\"Before removing missing text:\", len(df))\n",
        "df = df.dropna(subset=[\"text\"])\n",
        "print(\"After removing missing text:\", len(df))\n",
        "\n",
        "print(\"Before removing duplicates:\", len(df))\n",
        "df = df.drop_duplicates(subset=['user_id', 'gmap_id'])\n",
        "print(\"After removing duplicates:\", len(df))\n",
        "\n",
        "# Remove unnecessary columns\n",
        "useless = [\"name_x\", \"name_y\", \"time\", \"pics\", \"resp\", \"address\", \"relative_results\", \"state\", \"url\", \"latitude\", \"longitude\"]\n",
        "maybe = [\"description\", \"num_of_reviews\"]\n",
        "df = df.drop(columns=useless + maybe)\n",
        "\n",
        "# Remove missing ratings\n",
        "print(\"Before removing missing ratings:\", len(df))\n",
        "df = df.dropna(subset=['rating'])\n",
        "print(\"After removing missing ratings:\", len(df))\n",
        "\n",
        "# Save preprocessed data\n",
        "df.to_csv(\"merged.csv\", index=False)\n",
        "print(\"Preprocessed data saved to merged.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3779AsMbgRvy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "      <th>gmap_id</th>\n",
              "      <th>category</th>\n",
              "      <th>avg_rating</th>\n",
              "      <th>price</th>\n",
              "      <th>hours</th>\n",
              "      <th>MISC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.044905e+20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The Royal Group recently performed standard te...</td>\n",
              "      <td>0x89e02445cb9db457:0x37f42bff4edf7a43</td>\n",
              "      <td>[Security system supplier, Fire protection equ...</td>\n",
              "      <td>4.9</td>\n",
              "      <td>None</td>\n",
              "      <td>[[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...</td>\n",
              "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.120627e+20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I can't say enough great things about The Roya...</td>\n",
              "      <td>0x89e02445cb9db457:0x37f42bff4edf7a43</td>\n",
              "      <td>[Security system supplier, Fire protection equ...</td>\n",
              "      <td>4.9</td>\n",
              "      <td>None</td>\n",
              "      <td>[[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...</td>\n",
              "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.100483e+20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The Royal Group has done work for us over many...</td>\n",
              "      <td>0x89e02445cb9db457:0x37f42bff4edf7a43</td>\n",
              "      <td>[Security system supplier, Fire protection equ...</td>\n",
              "      <td>4.9</td>\n",
              "      <td>None</td>\n",
              "      <td>[[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...</td>\n",
              "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.061744e+20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The Royal Group was fantastic to work with. I ...</td>\n",
              "      <td>0x89e02445cb9db457:0x37f42bff4edf7a43</td>\n",
              "      <td>[Security system supplier, Fire protection equ...</td>\n",
              "      <td>4.9</td>\n",
              "      <td>None</td>\n",
              "      <td>[[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...</td>\n",
              "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.062387e+20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Have used in different houses, installing mult...</td>\n",
              "      <td>0x89e02445cb9db457:0x37f42bff4edf7a43</td>\n",
              "      <td>[Security system supplier, Fire protection equ...</td>\n",
              "      <td>4.9</td>\n",
              "      <td>None</td>\n",
              "      <td>[[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...</td>\n",
              "      <td>{'Accessibility': ['Wheelchair accessible entr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        user_id  rating                                               text  \\\n",
              "0  1.044905e+20     5.0  The Royal Group recently performed standard te...   \n",
              "2  1.120627e+20     5.0  I can't say enough great things about The Roya...   \n",
              "4  1.100483e+20     5.0  The Royal Group has done work for us over many...   \n",
              "6  1.061744e+20     5.0  The Royal Group was fantastic to work with. I ...   \n",
              "8  1.062387e+20     5.0  Have used in different houses, installing mult...   \n",
              "\n",
              "                                 gmap_id  \\\n",
              "0  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
              "2  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
              "4  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
              "6  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
              "8  0x89e02445cb9db457:0x37f42bff4edf7a43   \n",
              "\n",
              "                                            category  avg_rating price  \\\n",
              "0  [Security system supplier, Fire protection equ...         4.9  None   \n",
              "2  [Security system supplier, Fire protection equ...         4.9  None   \n",
              "4  [Security system supplier, Fire protection equ...         4.9  None   \n",
              "6  [Security system supplier, Fire protection equ...         4.9  None   \n",
              "8  [Security system supplier, Fire protection equ...         4.9  None   \n",
              "\n",
              "                                               hours  \\\n",
              "0  [[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...   \n",
              "2  [[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...   \n",
              "4  [[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...   \n",
              "6  [[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...   \n",
              "8  [[Thursday, 8AM–5PM], [Friday, 8AM–5PM], [Satu...   \n",
              "\n",
              "                                                MISC  \n",
              "0  {'Accessibility': ['Wheelchair accessible entr...  \n",
              "2  {'Accessibility': ['Wheelchair accessible entr...  \n",
              "4  {'Accessibility': ['Wheelchair accessible entr...  \n",
              "6  {'Accessibility': ['Wheelchair accessible entr...  \n",
              "8  {'Accessibility': ['Wheelchair accessible entr...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display sample of preprocessed data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# III. Modeling\n",
        "\n",
        "This section describes the models we implement for rating prediction. We start with simple baselines and progressively build more sophisticated models that incorporate text features and metadata.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A. Baseline Models\n",
        "\n",
        "We implement two simple baseline models to establish a performance floor:\n",
        "\n",
        "1. **Global Mean**: Predicts the average rating across all training examples\n",
        "2. **Item Mean (gmap_id mean)**: Predicts the average rating for each business (gmap_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 390441, Test size: 97611\n",
            "Global Mean: 4.3265\n",
            "Global Mean - MSE: 1.3808, Accuracy: 0.1689\n",
            "Item Mean - MSE: 1.2090, Accuracy: 0.4514\n",
            "Number of unique items in train: 10783\n",
            "Number of unseen items in test: 234\n"
          ]
        }
      ],
      "source": [
        "# Load data for baseline models\n",
        "df = pd.read_csv(\"merged.csv\", usecols=['user_id', 'rating', 'gmap_id'])\n",
        "\n",
        "# Clean and prepare data\n",
        "df = df.dropna(subset=['user_id', 'rating', 'gmap_id'])\n",
        "df['rating'] = df['rating'].astype(float)\n",
        "\n",
        "# Train/Test split\n",
        "train, test = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['rating']\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(train)}, Test size: {len(test)}\")\n",
        "\n",
        "# Baseline 1: Global Mean\n",
        "# Simply predict the average rating across all training examples\n",
        "global_mean = train['rating'].mean()\n",
        "print(f\"Global Mean: {global_mean:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "preds_global = [global_mean] * len(test)\n",
        "\n",
        "# Evaluate\n",
        "mse_global = mean_squared_error(test['rating'], preds_global)\n",
        "# Convert predictions to integers 1-5 for accuracy calculation\n",
        "preds_global_int = [min(5, max(1, int(round(p)))) for p in preds_global]\n",
        "acc_global = accuracy_score(test['rating'], preds_global_int)\n",
        "\n",
        "print(f\"Global Mean - MSE: {mse_global:.4f}, Accuracy: {acc_global:.4f}\")\n",
        "\n",
        "# Baseline 2: Item Mean (gmap_id mean)\n",
        "# Predict the average rating for each business\n",
        "item_avg = train.groupby('gmap_id')['rating'].mean()\n",
        "global_mean = train['rating'].mean()\n",
        "\n",
        "# Make predictions\n",
        "preds_item = []\n",
        "for gmap_id in test['gmap_id']:\n",
        "    if gmap_id in item_avg:\n",
        "        # Use item average if we've seen this business before\n",
        "        preds_item.append(item_avg[gmap_id])\n",
        "    else:\n",
        "        # Fall back to global mean for unseen businesses\n",
        "        preds_item.append(global_mean)\n",
        "\n",
        "# Evaluate\n",
        "mse_item = mean_squared_error(test['rating'], preds_item)\n",
        "preds_item_int = [min(5, max(1, int(round(p)))) for p in preds_item]\n",
        "acc_item = accuracy_score(test['rating'], preds_item_int)\n",
        "\n",
        "print(f\"Item Mean - MSE: {mse_item:.4f}, Accuracy: {acc_item:.4f}\")\n",
        "print(f\"Number of unique items in train: {len(item_avg)}\")\n",
        "print(f\"Number of unseen items in test: {sum(1 for gid in test['gmap_id'] if gid not in item_avg)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique users in train: 174161\n",
            "Users with only 1 review: 121350 (69.68%)\n",
            "Users with 2+ reviews: 52811 (30.32%)\n"
          ]
        }
      ],
      "source": [
        "# ========== Analysis: Why not User Mean? ==========\n",
        "user_review_counts = train.groupby('user_id').size()\n",
        "single_review_users = (user_review_counts == 1).sum()\n",
        "\n",
        "print(f\"Total unique users in train: {len(user_review_counts)}\")\n",
        "print(f\"Users with only 1 review: {single_review_users} ({100*single_review_users/len(user_review_counts):.2f}%)\")\n",
        "print(f\"Users with 2+ reviews: {len(user_review_counts) - single_review_users} ({100*(len(user_review_counts)-single_review_users)/len(user_review_counts):.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. Text-based Linear Model (Main Model #1)\n",
        "\n",
        "**Intuition**: The sentiment and expressions in text are most directly connected to ratings. Words, phrases, and sentiment expressions contained in review text provide key information for predicting the ratings assigned by users.\n",
        "\n",
        "We use:\n",
        "- **TF-IDF vectorization** to convert text into numerical features\n",
        "- **Ridge Regression** for regularization and to handle the high-dimensional feature space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 390440, Test size: 97610\n",
            "TF-IDF feature shape: (390440, 50000)\n",
            "Vocabulary size: 50000\n",
            "Text-based Model (Ridge) - MSE: 0.4724, Accuracy: 0.6481\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data for text-based model\n",
        "df = pd.read_csv(\"merged.csv\", usecols=['text', 'rating'])\n",
        "df = df.dropna(subset=['text', 'rating'])\n",
        "df['text'] = df['text'].astype(str)\n",
        "df['rating'] = df['rating'].astype(float)\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['rating'], test_size=0.2, random_state=42, stratify=df['rating']\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=50000,\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"TF-IDF feature shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
        "\n",
        "# Ridge Regression\n",
        "model_text = Ridge(alpha=1.0)\n",
        "model_text.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_text = model_text.predict(X_test_tfidf)\n",
        "y_pred_text_clamped = np.clip(np.round(y_pred_text), 1, 5)\n",
        "\n",
        "mse_text = mean_squared_error(y_test, y_pred_text)\n",
        "acc_text = accuracy_score(y_test, y_pred_text_clamped)\n",
        "\n",
        "print(f\"Text-based Model (Ridge) - MSE: {mse_text:.4f}, Accuracy: {acc_text:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Text + Metadata Model (Main Model #2)\n",
        "\n",
        "This model combines text features with metadata to capture both semantic content and contextual information about the business.\n",
        "\n",
        "**Features**:\n",
        "- **TF-IDF(text)**: Text vectorization\n",
        "- **avg_rating**: Average rating of the business (computed from training data only)\n",
        "- **category**: Business categories (BOW/one-hot encoding)\n",
        "- **hours**: Operating hours features (e.g., count of open hours)\n",
        "- **MISC**: Other feasible metadata features\n",
        "\n",
        "We use either **Ridge Regression** or **RandomForestRegressor** for this model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 390440, Test size: 97610\n",
            "TF-IDF shape: (390440, 50000)\n",
            "avg_rating feature - Train mean: 4.3265, Test mean: 4.3283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['Blood bank', 'Blood donation center', 'Blood testing service', 'Business school', 'Coin cashing machine', 'Fire alarm supplier', 'Haunted house', 'Labor union', 'Nurse practitioner', 'Orthotics & prosthetics service', 'Satellite communication service', 'Sports school', 'Vending machine supplier', 'Welding gas supplier', 'Welding supply store', 'Wetland'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category features shape: (390440, 1971), Unique categories: 1971\n",
            "Hours count - Train mean: 5.26, Test mean: 5.25\n",
            "MISC features extracted\n",
            "Combined feature shape - Train: (390440, 51976), Test: (97610, 51976)\n",
            "Text + Metadata Model (Ridge) - MSE: 0.4667, Accuracy: 0.6493\n"
          ]
        }
      ],
      "source": [
        "# Load data with metadata\n",
        "df = pd.read_csv(\"merged.csv\", usecols=['text', 'rating', 'gmap_id', 'category', 'avg_rating', 'hours', 'MISC'])\n",
        "\n",
        "# Clean and prepare data\n",
        "df = df.dropna(subset=['text', 'rating', 'gmap_id'])\n",
        "df['text'] = df['text'].astype(str)\n",
        "df['rating'] = df['rating'].astype(float)\n",
        "\n",
        "# Train/Test split\n",
        "df_train, df_test = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['rating']\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(df_train)}, Test size: {len(df_test)}\")\n",
        "\n",
        "# Feature 1: TF-IDF (text)\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=50000,\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(df_train['text'])\n",
        "X_test_tfidf = tfidf.transform(df_test['text'])\n",
        "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
        "\n",
        "# Feature 2: avg_rating (recomputed from training data only to avoid data leakage)\n",
        "train_avg_rating = df_train.groupby('gmap_id')['rating'].mean()\n",
        "global_avg = df_train['rating'].mean()\n",
        "\n",
        "df_train['avg_rating_feat'] = df_train['gmap_id'].map(train_avg_rating)\n",
        "df_train['avg_rating_feat'] = df_train['avg_rating_feat'].fillna(global_avg)\n",
        "\n",
        "df_test['avg_rating_feat'] = df_test['gmap_id'].map(train_avg_rating)\n",
        "df_test['avg_rating_feat'] = df_test['avg_rating_feat'].fillna(global_avg)\n",
        "print(f\"avg_rating feature - Train mean: {df_train['avg_rating_feat'].mean():.4f}, Test mean: {df_test['avg_rating_feat'].mean():.4f}\")\n",
        "\n",
        "# Feature 3: category (one-hot encoding)\n",
        "# Parse category strings into lists\n",
        "category_list_train = []\n",
        "for cat_str in df_train['category']:\n",
        "    if pd.isna(cat_str):\n",
        "        category_list_train.append([])\n",
        "    elif isinstance(cat_str, str):\n",
        "        if cat_str.startswith('['):\n",
        "            category_list_train.append(ast.literal_eval(cat_str))\n",
        "        else:\n",
        "            category_list_train.append([cat_str])\n",
        "    else:\n",
        "        category_list_train.append(cat_str if isinstance(cat_str, list) else [])\n",
        "\n",
        "category_list_test = []\n",
        "for cat_str in df_test['category']:\n",
        "    if pd.isna(cat_str):\n",
        "        category_list_test.append([])\n",
        "    elif isinstance(cat_str, str):\n",
        "        if cat_str.startswith('['):\n",
        "            category_list_test.append(ast.literal_eval(cat_str))\n",
        "        else:\n",
        "            category_list_test.append([cat_str])\n",
        "    else:\n",
        "        category_list_test.append(cat_str if isinstance(cat_str, list) else [])\n",
        "\n",
        "# One-hot encode categories\n",
        "mlb = MultiLabelBinarizer()\n",
        "X_train_category = mlb.fit_transform(category_list_train)\n",
        "X_test_category = mlb.transform(category_list_test)\n",
        "print(f\"Category features shape: {X_train_category.shape}, Unique categories: {len(mlb.classes_)}\")\n",
        "\n",
        "# Feature 4: hours (count of open hours)\n",
        "hours_count_train = []\n",
        "for hours_str in df_train['hours']:\n",
        "    if pd.isna(hours_str):\n",
        "        hours_count_train.append(0)\n",
        "    else:\n",
        "        if isinstance(hours_str, str):\n",
        "            hours_list = ast.literal_eval(hours_str)\n",
        "        else:\n",
        "            hours_list = hours_str\n",
        "        \n",
        "        if not isinstance(hours_list, list):\n",
        "            hours_count_train.append(0)\n",
        "        else:\n",
        "            open_count = 0\n",
        "            for day_info in hours_list:\n",
        "                if isinstance(day_info, list) and len(day_info) >= 2:\n",
        "                    if day_info[1] != 'Closed':\n",
        "                        open_count += 1\n",
        "            hours_count_train.append(open_count)\n",
        "\n",
        "hours_count_test = []\n",
        "for hours_str in df_test['hours']:\n",
        "    if pd.isna(hours_str):\n",
        "        hours_count_test.append(0)\n",
        "    else:\n",
        "        if isinstance(hours_str, str):\n",
        "            hours_list = ast.literal_eval(hours_str)\n",
        "        else:\n",
        "            hours_list = hours_str\n",
        "        \n",
        "        if not isinstance(hours_list, list):\n",
        "            hours_count_test.append(0)\n",
        "        else:\n",
        "            open_count = 0\n",
        "            for day_info in hours_list:\n",
        "                if isinstance(day_info, list) and len(day_info) >= 2:\n",
        "                    if day_info[1] != 'Closed':\n",
        "                        open_count += 1\n",
        "            hours_count_test.append(open_count)\n",
        "\n",
        "df_train['hours_count'] = hours_count_train\n",
        "df_test['hours_count'] = hours_count_test\n",
        "print(f\"Hours count - Train mean: {df_train['hours_count'].mean():.2f}, Test mean: {df_test['hours_count'].mean():.2f}\")\n",
        "\n",
        "# Feature 5: MISC (extract accessibility, amenities, and key count)\n",
        "has_accessibility_train = []\n",
        "has_amenities_train = []\n",
        "misc_keys_count_train = []\n",
        "\n",
        "for misc_str in df_train['MISC']:\n",
        "    if pd.isna(misc_str):\n",
        "        has_accessibility_train.append(0)\n",
        "        has_amenities_train.append(0)\n",
        "        misc_keys_count_train.append(0)\n",
        "    else:\n",
        "        if isinstance(misc_str, str):\n",
        "            if misc_str.startswith('{'):\n",
        "                misc_dict = ast.literal_eval(misc_str)\n",
        "            else:\n",
        "                misc_dict = {}\n",
        "        else:\n",
        "            misc_dict = misc_str if isinstance(misc_str, dict) else {}\n",
        "        \n",
        "        has_accessibility_train.append(1 if 'Accessibility' in misc_dict else 0)\n",
        "        has_amenities_train.append(1 if 'Amenities' in misc_dict or 'Amenity' in misc_dict else 0)\n",
        "        misc_keys_count_train.append(len(misc_dict) if isinstance(misc_dict, dict) else 0)\n",
        "\n",
        "has_accessibility_test = []\n",
        "has_amenities_test = []\n",
        "misc_keys_count_test = []\n",
        "\n",
        "for misc_str in df_test['MISC']:\n",
        "    if pd.isna(misc_str):\n",
        "        has_accessibility_test.append(0)\n",
        "        has_amenities_test.append(0)\n",
        "        misc_keys_count_test.append(0)\n",
        "    else:\n",
        "        if isinstance(misc_str, str):\n",
        "            if misc_str.startswith('{'):\n",
        "                misc_dict = ast.literal_eval(misc_str)\n",
        "            else:\n",
        "                misc_dict = {}\n",
        "        else:\n",
        "            misc_dict = misc_str if isinstance(misc_str, dict) else {}\n",
        "        \n",
        "        has_accessibility_test.append(1 if 'Accessibility' in misc_dict else 0)\n",
        "        has_amenities_test.append(1 if 'Amenities' in misc_dict or 'Amenity' in misc_dict else 0)\n",
        "        misc_keys_count_test.append(len(misc_dict) if isinstance(misc_dict, dict) else 0)\n",
        "\n",
        "df_train['has_accessibility'] = has_accessibility_train\n",
        "df_train['has_amenities'] = has_amenities_train\n",
        "df_train['misc_keys_count'] = misc_keys_count_train\n",
        "\n",
        "df_test['has_accessibility'] = has_accessibility_test\n",
        "df_test['has_amenities'] = has_amenities_test\n",
        "df_test['misc_keys_count'] = misc_keys_count_test\n",
        "print(\"MISC features extracted\")\n",
        "\n",
        "# Combine all features\n",
        "num_features_train = df_train[['avg_rating_feat', 'hours_count', 'has_accessibility', 'has_amenities', 'misc_keys_count']].values\n",
        "num_features_test = df_test[['avg_rating_feat', 'hours_count', 'has_accessibility', 'has_amenities', 'misc_keys_count']].values\n",
        "\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_category, num_features_train])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_category, num_features_test])\n",
        "print(f\"Combined feature shape - Train: {X_train_combined.shape}, Test: {X_test_combined.shape}\")\n",
        "\n",
        "# Model: Ridge Regression\n",
        "model_combined_ridge = Ridge(alpha=1.0)\n",
        "model_combined_ridge.fit(X_train_combined, df_train['rating'])\n",
        "\n",
        "y_pred_ridge = model_combined_ridge.predict(X_test_combined)\n",
        "y_pred_ridge_int = np.clip(np.round(y_pred_ridge), 1, 5)\n",
        "\n",
        "mse_ridge = mean_squared_error(df_test['rating'], y_pred_ridge)\n",
        "acc_ridge = accuracy_score(df_test['rating'], y_pred_ridge_int)\n",
        "\n",
        "print(f\"Text + Metadata Model (Ridge) - MSE: {mse_ridge:.4f}, Accuracy: {acc_ridge:.4f}\")\n",
        "\n",
        "# Model: Random Forest Regressor\n",
        "model_combined_rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Convert sparse matrix to CSR format for indexing, then to dense for Random Forest\n",
        "X_train_combined_csr = X_train_combined.tocsr()\n",
        "\n",
        "if X_train_combined_csr.shape[0] > 100000:\n",
        "    # Use a sample if dataset is too large\n",
        "    sample_idx = np.random.choice(X_train_combined_csr.shape[0], 100000, replace=False)\n",
        "    X_train_sample = X_train_combined_csr[sample_idx].toarray()\n",
        "    y_train_sample = df_train['rating'].iloc[sample_idx].values\n",
        "    model_combined_rf.fit(X_train_sample, y_train_sample)\n",
        "    y_pred_rf = model_combined_rf.predict(X_test_combined.toarray())\n",
        "else:\n",
        "    model_combined_rf.fit(X_train_combined_csr.toarray(), df_train['rating'])\n",
        "    y_pred_rf = model_combined_rf.predict(X_test_combined.toarray())\n",
        "\n",
        "y_pred_rf_int = np.clip(np.round(y_pred_rf), 1, 5)\n",
        "\n",
        "mse_rf = mean_squared_error(df_test['rating'], y_pred_rf)\n",
        "acc_rf = accuracy_score(df_test['rating'], y_pred_rf_int)\n",
        "\n",
        "print(f\"Text + Metadata Model (Random Forest) - MSE: {mse_rf:.4f}, Accuracy: {acc_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. BERT Embedding Model\n",
        "\n",
        "**Explanation**: BERT (Bidirectional Encoder Representations from Transformers) provides richer semantic representation of text compared to TF-IDF. It captures contextual word meanings and can better understand the sentiment and nuances in review text.\n",
        "\n",
        "We use **SBERT (Sentence-BERT)** to generate sentence embeddings, which are then fed into a Linear Regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading SBERT model...\n",
            "Generating embeddings for 50000 training samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1563/1563 [01:59<00:00, 13.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 3051/3051 [03:14<00:00, 15.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT Embedding Model - MSE: 0.6408, Accuracy: 0.5741\n"
          ]
        }
      ],
      "source": [
        "# Load SBERT model\n",
        "print(\"Loading SBERT model...\")\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Use a subset for efficiency (BERT is computationally expensive)\n",
        "sample_size = min(50000, len(df_train))\n",
        "sample_idx = np.random.choice(len(df_train), sample_size, replace=False)\n",
        "\n",
        "print(f\"Generating embeddings for {sample_size} training samples...\")\n",
        "X_train_bert = sbert_model.encode(\n",
        "    df_train['text'].iloc[sample_idx].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    batch_size=32\n",
        ")\n",
        "y_train_bert = df_train['rating'].iloc[sample_idx].values\n",
        "\n",
        "print(f\"Generating embeddings for test set...\")\n",
        "X_test_bert = sbert_model.encode(\n",
        "    df_test['text'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Linear Regression on BERT embeddings\n",
        "model_bert = LinearRegression()\n",
        "model_bert.fit(X_train_bert, y_train_bert)\n",
        "\n",
        "y_pred_bert = model_bert.predict(X_test_bert)\n",
        "y_pred_bert_clamped = np.clip(np.round(y_pred_bert), 1, 5)\n",
        "\n",
        "mse_bert = mean_squared_error(df_test['rating'], y_pred_bert)\n",
        "acc_bert = accuracy_score(df_test['rating'], y_pred_bert_clamped)\n",
        "\n",
        "print(f\"BERT Embedding Model - MSE: {mse_bert:.4f}, Accuracy: {acc_bert:.4f}\")\n",
        "bert_available = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## E. Model Comparison\n",
        "\n",
        "Below is a comprehensive comparison of all models we implemented:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "results = {\n",
        "    'Model': [\n",
        "        'Global Mean (Baseline)',\n",
        "        'Item Mean (Baseline)',\n",
        "        'Text-based (TF-IDF + Ridge)',\n",
        "        'Text + Metadata (Ridge)',\n",
        "        'Text + Metadata (Random Forest)',\n",
        "    ],\n",
        "    'MSE': [\n",
        "        mse_global,\n",
        "        mse_item,\n",
        "        mse_text,\n",
        "        mse_ridge,\n",
        "        mse_rf,\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        acc_global,\n",
        "        acc_item,\n",
        "        acc_text,\n",
        "        acc_ridge,\n",
        "        acc_rf,\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Add BERT if available\n",
        "if bert_available:\n",
        "    results['Model'].append('BERT Embedding (SBERT + Linear Regression)')\n",
        "    results['MSE'].append(mse_bert)\n",
        "    results['Accuracy'].append(acc_bert)\n",
        "\n",
        "comparison_df = pd.DataFrame(results)\n",
        "comparison_df = comparison_df.sort_values('MSE')\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "comparison_df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
